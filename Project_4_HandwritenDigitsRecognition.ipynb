{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7bEu9omyJOakIXFfU8ARG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jocker1854/Machine-Learning-Projects/blob/main/Project_4_HandwritenDigitsRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UWu9Vva_SUnh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "5L0kElKPUAqH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=ToTensor())\n",
        "test_data = datasets.MNIST(root='data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87bcpGKJURAj",
        "outputId": "7ced0848-17cd-4a1c-f8bb-54b7d9725828"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.96MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1),\n",
        "    'test': DataLoader(test_data,\n",
        "                       batch_size=100,\n",
        "                       shuffle=False,\n",
        "                       num_workers=1),\n",
        "    }"
      ],
      "metadata": {
        "id": "ZDXeZbsDUoH6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgr0Nnd5V2Q_",
        "outputId": "b235c7e5-99e3-466c-bab9-9e4b53605a5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7cb743756350>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7cb662803c50>}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGKV491kWt9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(in_features=320, out_features=50)\n",
        "        self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.dropout(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "sK7Xxd9BSuoU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "31u_xUvrYDWi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, targets) in enumerate(loaders['train']):\n",
        "    data, targets = data.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')"
      ],
      "metadata": {
        "id": "sRlm-aClYNAb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, targets in loaders['test']:\n",
        "      data, targets = data.to(device), targets.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, targets).item()\n",
        "      pred = output.argmax(1, keepdim=True)\n",
        "      correct += pred.eq(targets.data.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(loaders['test'].dataset)\n",
        "  print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')"
      ],
      "metadata": {
        "id": "kRrcHcTiaZUw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xZHn6f_2a7zq",
        "outputId": "d43d586e-386c-48e4-9a19-302a541a5625"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303479\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.293327\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.170327\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.014255\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.892732\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.763484\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.803308\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.752465\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.736208\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.680120\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.617347\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.718282\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.684335\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.617519\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.652610\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.625243\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.609967\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.629511\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.643173\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.605441\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.582532\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.601920\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.629219\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.534876\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.626174\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.620129\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.638966\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.572989\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.578634\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.643902\n",
            "Test set: Average loss: 0.0152, Accuracy: 9389/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.633961\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.556518\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.541345\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.617448\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.566361\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.555118\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.571419\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.556131\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.546159\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.580563\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.580980\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.615764\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.625231\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.551823\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.595195\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.564872\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.575034\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.622908\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.590700\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.599313\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.528656\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.549896\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.513264\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.618564\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.583195\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.577552\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.550202\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.530084\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.541746\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.545429\n",
            "Test set: Average loss: 0.0151, Accuracy: 9549/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.522977\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.568288\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.571243\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.588109\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.584349\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.578993\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.548439\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.543528\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.551648\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.505961\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.534411\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.536446\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.548462\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.548010\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.552809\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.548510\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.532294\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.547268\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.504640\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.547560\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.569609\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.585970\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.550956\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.566589\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.552626\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.546697\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.521832\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.597202\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.572626\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.575548\n",
            "Test set: Average loss: 0.0150, Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.516001\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.552609\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.566115\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.557002\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.573287\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.537993\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.526889\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.556970\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.519045\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.519210\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a8c428eb9972>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-853488e9b72d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "\n",
        "data, target = test_data[876]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(1, keepdim=True).item()\n",
        "\n",
        "print(f'Prediction: {prediction}')\n",
        "\n",
        "# Squeeze the channel dimension before plotting\n",
        "plt.imshow(data.squeeze(0).squeeze(0).cpu().numpy(), cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "3C9dFgbYb9XZ",
        "outputId": "ae699191-46b3-49ff-f11c-d84da53b906f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}